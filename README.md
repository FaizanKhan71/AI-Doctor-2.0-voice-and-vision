# ğŸ¥ AI Doctor Assistant

Advanced Medical Image Analysis with Voice Interaction - An AI-powered healthcare assistant that combines computer vision and natural language processing to provide medical insights.

## âœ¨ Features

- ğŸ¤ **Voice Recognition**: Speak naturally about your symptoms
- ğŸ‘ï¸ **Medical Image Analysis**: AI-powered analysis of medical images
- ğŸ”Š **Audio Response**: Natural-sounding voice responses
- ğŸ©º **Detailed Analysis**: Comprehensive medical assessments
- ğŸ“± **Responsive Design**: Works on desktop and mobile devices

## ğŸš€ Live Demo

[Visit the live application](https://ai-doctor-2-0-voice-and-vision.vercel.app)

## ğŸ› ï¸ Technology Stack

- **Frontend**: Gradio with custom CSS animations
- **AI Models**: 
  - Groq (Whisper for speech-to-text, Llama for image analysis)
  - ElevenLabs (Text-to-speech)
- **Backend**: Python
- **Deployment**: Vercel

## ğŸ“‹ Prerequisites

- Python 3.8+
- Groq API Key ([Get it here](https://console.groq.com/))
- ElevenLabs API Key ([Get it here](https://elevenlabs.io/))

## ğŸ”§ Local Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ai-doctor-assistant.git
cd ai-doctor-assistant
```

### 2. Install Dependencies

#### Using pip:
```bash
pip install -r requirements.txt
```

#### Using pipenv:
```bash
pipenv install
pipenv shell
```

### 3. Set Up Environment Variables

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key_here
ELEVEN_API_KEY=your_elevenlabs_api_key_here
```

### 4. Install System Dependencies

#### Windows:
1. Download FFmpeg from [FFmpeg Downloads](https://ffmpeg.org/download.html)
2. Extract and add to PATH
3. Install PortAudio from [PortAudio Downloads](http://www.portaudio.com/download.html)

#### macOS:
```bash
brew install ffmpeg portaudio
```

#### Linux (Ubuntu/Debian):
```bash
sudo apt update
sudo apt install ffmpeg portaudio19-dev
```

### 5. Run the Application

```bash
python app.py
```

The application will be available at `http://localhost:7860`

## ğŸŒ Deployment Instructions

### Deploy to Vercel

#### Method 1: Using Vercel CLI

1. **Install Vercel CLI**:
   ```bash
   npm install -g vercel
   ```

2. **Login to Vercel**:
   ```bash
   vercel login
   ```

3. **Deploy**:
   ```bash
   vercel
   ```

4. **Set Environment Variables**:
   ```bash
   vercel env add GROQ_API_KEY
   vercel env add ELEVEN_API_KEY
   ```

5. **Redeploy with Environment Variables**:
   ```bash
   vercel --prod
   ```

#### Method 2: Using Vercel Dashboard

1. **Connect GitHub Repository**:
   - Go to [Vercel Dashboard](https://vercel.com/dashboard)
   - Click "New Project"
   - Import your GitHub repository

2. **Configure Environment Variables**:
   - In project settings, go to "Environment Variables"
   - Add:
     - `GROQ_API_KEY`: Your Groq API key
     - `ELEVEN_API_KEY`: Your ElevenLabs API key

3. **Deploy**:
   - Vercel will automatically deploy your application
   - Your app will be available at `https://your-project-name.vercel.app`

### Deploy to Other Platforms

#### Hugging Face Spaces
1. Create a new Space on [Hugging Face](https://huggingface.co/spaces)
2. Choose "Gradio" as the SDK
3. Upload your files
4. Add secrets in Space settings:
   - `GROQ_API_KEY`
   - `ELEVEN_API_KEY`

#### Railway
1. Connect your GitHub repository to [Railway](https://railway.app)
2. Add environment variables in the dashboard
3. Deploy automatically

## ğŸ“ Project Structure

```
ai-doctor-assistant/
â”œâ”€â”€ app.py                      # Main Gradio application
â”œâ”€â”€ brain_of_the_doctor.py      # Image analysis logic
â”œâ”€â”€ voice_of_the_patient.py     # Speech-to-text processing
â”œâ”€â”€ voice_of_the_doctor.py      # Text-to-speech processing
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ vercel.json                # Vercel configuration
â”œâ”€â”€ .env                       # Environment variables (local)
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ acne.jpg                   # Sample medical image
â”œâ”€â”€ dandruff-optimized.webp    # Sample medical image
â””â”€â”€ skin_rash.jpg              # Sample medical image
```

## ğŸ”’ Security & API Keys

**IMPORTANT**: This repository is safe to make public because:
- âœ… API keys are stored in environment variables (`.env` file)
- âœ… `.env` file is excluded via `.gitignore`
- âœ… No hardcoded credentials in the source code
- âœ… All sensitive data is handled through environment variables

### ğŸ”‘ API Keys Setup

#### Groq API Key
1. Visit [Groq Console](https://console.groq.com/)
2. Sign up/Login
3. Generate an API key
4. Add to your `.env` file: `GROQ_API_KEY=your_key_here`

#### ElevenLabs API Key
1. Visit [ElevenLabs](https://elevenlabs.io/)
2. Sign up/Login
3. Go to Profile â†’ API Keys
4. Generate an API key
5. Add to your `.env` file: `ELEVEN_API_KEY=your_key_here`

## ğŸ¯ Usage Instructions

1. **Record Audio**: Click the microphone and describe your symptoms
2. **Upload Image**: Select a clear medical image for analysis
3. **Submit**: Click "Analyze with AI Doctor" button
4. **Review Results**: Read the analysis and listen to the audio response

## âš ï¸ Important Disclaimers

- This application is for **educational purposes only**
- **Always consult qualified healthcare professionals** for medical advice
- Do not use this as a substitute for professional medical diagnosis
- The AI responses are based on image analysis and should not be considered definitive medical opinions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Faizan Khan**
- GitHub: [@faizankhan2595](https://github.com/faizankhan2595)
- LinkedIn: [Faizan Khan](https://linkedin.com/in/faizan-khan-ai)

## ğŸš€ Quick Deploy to Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/faizankhan2595/ai-doctor-2.0-voice-and-vision&env=GROQ_API_KEY,ELEVEN_API_KEY)

1. Click the deploy button above
2. Add your API keys in environment variables
3. Deploy instantly!

## ğŸ™ Acknowledgments

- Groq for providing fast AI inference
- ElevenLabs for natural voice synthesis
- Gradio for the amazing web interface framework
- The open-source community for various tools and libraries

## ğŸ“ Support

If you encounter any issues or have questions:
1. Check the [Issues](https://github.com/yourusername/ai-doctor-assistant/issues) page
2. Create a new issue if your problem isn't already reported
3. Provide detailed information about the error and your environment

---

**Built with â¤ï¸ for accessible healthcare technology**